{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=LANGCHAIN_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(input_1):\n",
    "    return input_1 + \" First Function \"\n",
    "\n",
    "def function_2(input_2):\n",
    "    return input_2 + \"to Second Function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph\n",
    "\n",
    "# Define a Langchain graph\n",
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"node_1\", function_1)\n",
    "workflow.add_node(\"node_2\", function_2)\n",
    "\n",
    "workflow.add_edge('node_1', 'node_2')\n",
    "\n",
    "workflow.set_entry_point(\"node_1\")\n",
    "workflow.set_finish_point(\"node_2\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am moving from First Function to Second Function'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke('I am moving from')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'node_1':\n",
      "---\n",
      "I am moving from First Function \n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'node_2':\n",
      "---\n",
      "I am moving from First Function to Second Function\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = 'I am moving from'\n",
    "for output in app.stream(input):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating LLM call in the LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi there! ðŸ‘‹\\n\\nWhat can I do for you today? ðŸ˜Š\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 11, 'total_tokens': 28, 'completion_time': 0.030909091, 'prompt_time': 0.001919478, 'queue_time': 0.23072616099999999, 'total_time': 0.032828569}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-442ec83f-944b-4e0d-a8fe-062b6c34c29c-0', usage_metadata={'input_tokens': 11, 'output_tokens': 17, 'total_tokens': 28})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model_name=\"Gemma2-9b-It\")\n",
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(input_1):\n",
    "    complete_query = \"Your task is to provide only the topic based on the user query. \\\n",
    "        Only output the topic among: [Japan , Sports]. Don't include reasoning. Following is the user query: \" + input_1\n",
    "    response = llm.invoke(complete_query)\n",
    "    return response.content\n",
    "\n",
    "def function_2(input_2):\n",
    "    TOPIC_UPPER = input_2.upper()\n",
    "    response = f\"Here is the topic in UPPER case: {TOPIC_UPPER}\"\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Langchain graph\n",
    "workflow = Graph()\n",
    "\n",
    "workflow.add_node(\"Agent\", function_1)\n",
    "workflow.add_node(\"tool\", function_2)\n",
    "\n",
    "workflow.add_edge('Agent', 'tool')\n",
    "\n",
    "workflow.set_entry_point(\"Agent\")\n",
    "workflow.set_finish_point(\"tool\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is the topic in UPPER case: JAPAN \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Tell me about Japan's Industrial Growth\"\n",
    "app.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'Agent':\n",
      "---\n",
      "Japan \n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tool':\n",
      "---\n",
      "Here is the topic in UPPER case: JAPAN \n",
      "\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output in app.stream(query):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JAGADEESHNAIKPALTHYA\\langgraph-end-to-end\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm doing well, thank you! As an AI, I don't have feelings, but I'm ready to assist you with any questions or tasks you may have.\\n\\nHow can I help you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 13, 'total_tokens': 61, 'completion_time': 0.087272727, 'prompt_time': 0.001901197, 'queue_time': 0.234063152, 'total_time': 0.089173924}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f1cd62ea-58c5-42d7-8cab-f956a6feb5fd-0', usage_metadata={'input_tokens': 13, 'output_tokens': 48, 'total_tokens': 61})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('Hii How are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=DirectoryLoader(\"../data\",glob=\"./*.txt\",loader_cls=TextLoader)\n",
    "docs=loader.load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "new_docs = text_splitter.split_documents(documents=docs)\n",
    "doc_strings = [doc.page_content for doc in new_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JAGADEESHNAIKPALTHYA\\langgraph-end-to-end\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:83\u001b[39m, in \u001b[36mChroma.__init__\u001b[39m\u001b[34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m db = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m retriever = db.as_retriever(search_kwargs={\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JAGADEESHNAIKPALTHYA\\langgraph-end-to-end\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    886\u001b[39m metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JAGADEESHNAIKPALTHYA\\langgraph-end-to-end\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:817\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    785\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m    786\u001b[39m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[32m   (...)\u001b[39m\u001b[32m    796\u001b[39m     **kwargs: Any,\n\u001b[32m    797\u001b[39m ) -> Chroma:\n\u001b[32m    798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[32m    799\u001b[39m \n\u001b[32m    800\u001b[39m \u001b[33;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    815\u001b[39m \u001b[33;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[32m    816\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m817\u001b[39m     chroma_collection = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    827\u001b[39m         ids = [\u001b[38;5;28mstr\u001b[39m(uuid.uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JAGADEESHNAIKPALTHYA\\langgraph-end-to-end\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:214\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    213\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JAGADEESHNAIKPALTHYA\\langgraph-end-to-end\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:86\u001b[39m, in \u001b[36mChroma.__init__\u001b[39m\u001b[34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     87\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import chromadb python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install chromadb`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m     )\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mself\u001b[39m._client_settings = client_settings\n",
      "\u001b[31mImportError\u001b[39m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "source": [
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

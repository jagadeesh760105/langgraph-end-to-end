{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0424b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GOOGLE_API_KEY\"]= GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e6fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc8282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Verse 1)\n",
      "The data streams, a raging flood,\n",
      "A sea of text, misunderstood.\n",
      "To find the gems, the pearls so bright,\n",
      "Required a tool, a guiding light.\n",
      "Then came a whisper, low and deep,\n",
      "Of LangChain's promise, secrets to keep,\n",
      "To tame the chaos, bring it to heel,\n",
      "And harvest knowledge, make it real.\n",
      "\n",
      "(Verse 2)\n",
      "With LLMs vast, a mighty power,\n",
      "It chains them closely, hour by hour.\n",
      "Prompts it crafts with careful hand,\n",
      "To glean insights, across the land.\n",
      "From documents, a swirling maze,\n",
      "It extracts meaning, in a haze\n",
      "Of clever logic, code so neat,\n",
      "A symphony of algorithms sweet.\n",
      "\n",
      "(Verse 3)\n",
      "The chains it forges, strong and true,\n",
      "Connect the models, old and new.\n",
      "Retrieval systems, finely spun,\n",
      "To fetch the facts, before the run\n",
      "Of queries posed, both big and small,\n",
      "It answers them, it stands up tall.\n",
      "Agents it builds, with purpose clear,\n",
      "To solve the problems, far and near.\n",
      "\n",
      "(Verse 4)\n",
      "The memory module, ever keen,\n",
      "Retains the context, fresh and clean.\n",
      "No information lost to time,\n",
      "A flowing river, in its prime.\n",
      "Through chains of thought, it carefully weaves,\n",
      "A tapestry of words that believes\n",
      "In reason's power, logic's might,\n",
      "To bring forth answers, shining bright.\n",
      "\n",
      "(Verse 5)\n",
      "So hail LangChain, a wondrous thing,\n",
      "That makes the data sweetly sing.\n",
      "A bridge it builds, between the code,\n",
      "And knowledge vast, along the road.\n",
      "For those who seek, with minds so keen,\n",
      "To unlock secrets, yet unseen,\n",
      "LangChain awaits, a loyal friend,\n",
      "Until the very, hopeful end.\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"Write a ballad about LangChain\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f609d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embed_query('hii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e520646",
   "metadata": {},
   "source": [
    "### Let's Create a Retriever now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95bffc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28425d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
